% !Mode:: "TeX:UTF-8"

\chapter{Deep Learning Based Model for Runtime Analysis}
In this chapter we describe our proposed deep learning based method for 3D IC runtime analysis.
First, we briefly review the work of \cite{Zhang2016Fast}, for their model
will be partially used in our work.
Then we describe the models used in our proposed method. They are modified from some modern
CNNs used in computer vision jobs such as object detection and face recognition.
We will specify these models' structure, and how they differ from their inceptions
to be fitted into 3D IC reliability runtime analysis jobs.
Finally, we apply this method to the dataset in \cite{Zhang2016Fast},
get a promising accuracy and economic computing cost.
The details of this experiment are demonstrated in the last section.

\section{A Fully-Connected ANN Model}
Since FEM based models are computational expensive, we may wish to figure out whether
it exist a much simpler and faster map $f: T \to F_{\left\{ x,y,z \right\}}$
\footnote{$T$ and $F_{\left\{ x,y,z \right\}}$ are notations in section \ref{sec::thermal}, which means
$f$ is a map from IC temperature distribution to its relevant thermal stress}
that could be used in runtime scenario.
\cite{Zhang2016Fast} proposed a two-layers fully connected ANN model with hand-crafted
feature extraction, then train this model by large amount of $(T \to F_{\left\{x,y,x\right\}})$ data
generated off-line by FEM based model. 
The ANN model achieved accuracy of $RMSE: 0.0779$ in the normed test set, and fast enough 
($300 TSVs / 0.06s$ @ 2.4 GHz, 1 core) to be applied
in runtime scenario due to simplicity of the ANN model they used.
The highlights of their work include:

\subsection{FEM Generated Temperature-Stress Dataset} \label{sec::FEM-data}
To best of our current knowledge, \cite{Zhang2016Fast} is the very first work that provide a
accuracy and substantial dataset of 3D IC temperature-stress info.
They have built a two-layer 3D IC model with $12\times12$ TSVs uniformly placed
in the whole chip using the FEM based software \textit{COMSOL}.
The size of whole chip is $1cm\times1cm\times300\mu m$, and it is
divided into $4\times4$ same sized blocks to represent $16$ cores,
both of the two layers are $1cm\times1cm\times100\mu m$. 
For the TSV structure, they set the values of $r_i$ and $r_o$
as $20\mu m$ and $24\mu m$, respectively. They also couple
the solid heat conduction field and the solid mechanical field.

Applying different thermal distribution to above model, they generated $N=2736$
pairs of temperature-stress data that can be used in neural network training.
The format of their data is like table \ref{tab::t-sformat}
\footnote{These data in tabular are randomly selected in dataset of \cite{Zhang2016Fast}}.
Note that the coordinate of $z$ is always $0$, because the dies in 3D IC are
extremely thin.

\begin{table}[htb]
\centering
\begin{tabularx}{30em}{*{3}{>{\centering\arraybackslash}X} *{2}{|c}}
    \toprule
    \multicolumn{3}{c|}{Coordinate($m$)} & 
    \multirow{2}{*}{Temperature($K$)} & 
    \multirow{2}{*}{Stress($N/m^2$)} \\
    \cmidrule{1-3}
    x & y & z && \\
    \midrule
    8.4631E-5 & 9.5289E-5 & 0 & 359.1351 & 31150.4105 \\
    2.0725E-4 & 1.2576E-4 & 0 & 359.0865 & 58634.6722 \\
    9.5824E-5 & 2.0547E-4 & 0 & 359.0865 & 62021.0153 \\
    \bottomrule
\end{tabularx}
\caption{Format of Temperature-Stress Dataset}
\label{tab::t-sformat}
\end{table} 

\subsection{Hand-Crafted Feature Extraction} \label{sec::hc-fe}
Based on these observations:
\begin{itemize}
    % \setlength\itemsep{1em}
    \item Reliability of 3D IC with TSV structure strongly depends on 
          the \textit{maximum} of thermal stress;
    \item The maximum stress always appears within a certain distance from the TSV center.
          Large mount of temperature informations are redundance;
    \item Having a round structure,
          the TSV and the areas around it have a \textit{rotational symmetry
          property}: two different thermal/stress maps can be the exactly
          the same after a certain amount of rotation;
\end{itemize}
% TODO: add image for TSV rotation
\cite{Zhang2016Fast} proposed a feature extraction process: rotate the temperature distribution
around each TSVs by aligning their maximum temperature line to eliminate the rotation symmetry,
then interpolate these data points to a continuous true value matrix, finally select temperature
values uniformly from this interpolated matrix by the Cartesian distance. The procedure can be
illustrated as figure TODO.

After above precess, the raw text data can be transfered to vectors 
$\mathbf{x}_{i=1,\cdots,N} \in \mathbb{R}^{320}$, with relevant maximum stress 
$y_{i=1,\cdots,N} \in \mathbb{R}$,
we may train the ANN model with these dataset.

\subsection{A Fast Fully-Connected ANN Model}
The ANN model used in this method uses a simple two layers structure. 
The input layer gets $55$ neurons, and hidden layer $15$ neurons, finally a $1$ neuron layer
to output the approximated maximum stress value.
Training with $2400$ samples randomly selected from whole temperature-stress dataset,
the model achieves the accuracy of $RMSE: 0.0779$ in the $300$ samples test set 
which is also selected randomly with no recurrence to training set after $1000$ iterations.

\section{Automatic Feature Extraction via CNN}
Although the hand-crafted feature extraction procedure in \ref{sec::hc-fe} is 
practically proved working in 3D IC reliability analysis jobs,
we may archive a better accuracy by refine this feature extraction procedure.
We believe that the room of refinement still exists, for these reasons:
\begin{itemize}
    % \setlength\itemsep{1em}
    \item Since one may not intuitively give the stress value $y\in\mathbb{R}$
    by a temperature distribution, the feature mapping relationship could be
    much more complex than na\"ive uniform selection and rotational symmetry proposed
    in section \ref{sec::hc-fe};
    \item Rotating input data is a common data augmentation procedure in neural
    network training\cite{Goodfellow2016Deep}, 
    so the maximum temperature line alignment could be unnecessary,
    even harm to the accuracy of result;
    \item As described in section \ref{sec::hc-fe}, maximum stress is not related to
    the whole temperature distribution but little around TSVs. But in fully-connected
    ANN model, the output $\mathbf{y}\in\mathbb{R}^n$ depends on all of model input 
    $\mathbf{x}\in\mathbb{R}^m$. This may introduce strong noise into result.
\end{itemize}

As described in section \ref{sec::intro_cnn}, convolutional network has been proved as
an effective local feature extraction method. Due to its property of sparse interaction
and parameter sharing, CNN model could be quite suitable for 3D IC reliability analysis jobs.

\subsection{Data Preprocessing}
In this work, we use the same temperature-stress dataset in \cite{Zhang2016Fast}. 
For facilitating the procedure of convolution feature extraction, 
the inputs of CNN should be well formatted. 
The data preprocessing steps are listed as following:

\begin{description}[labelsep=0.5em]
    \item[Data Interpolation] Follow \cite{Zhang2016Fast}, we interpolate the $N$ data points 
    around each TSV $\left(x,y,temp\right)_{1,\cdots,N}$
    to a temperature matrix $\mathbf{T}\in\mathbb{R}^2$.
    Note that distribution of valid data points generated in FEM model is dense in
    the area around TSVs, and it becomes sparser where far from TSVs.
    % TODO:  add image of temperature data points distribution
    Based on this observation, we only take $N$ temperature points whose distance to its nearing TSV 
    $r \le r_{thresh} \times l$ for interpolation. Where $l$ denotes the distance of adjacent TSVs,
    $r_{thresh}$ the distance threshold ratio for data points selection. \label{itm::interp}
    In this work, we set $r_{thresh}=0.2$, and get $N=91$ as a result.
    
    \item[Train-Val Splitting] Since \cite{Zhang2016Fast} didn't give their partition of dataset,
    we use the toolbox \texttt{scikit-learn} to split the whole dataset into train set and test set.
    The ratio of train / test is $0.7 / 0.3$, precisely there are $1915$ samples in train set and
    $821$ samples in test set.
    
    \item[Whitening] It has been long known that the network training converges faster 
    if its inputs are whitened â€“ i.e., 
    linearly transformed to have zero means and unit variances, and decorrelated \cite{orr2003neural}.
    Thus we perform this linear transport to interpolated data matrix: 
    $\mathbf{T}^* = \frac{\mathbf{T} - \mathbf{M}}{\sigma}$, 
    where $\mathbf{M}$ is the mean value matrix of the training set, $\sigma$ the variances of the training set.
     
\end{description}

\subsection{A LeNet Based Model}
LeNet is a very early 
\subsection{A Tiny VGG-Net Based Model}

\section{CNN-Stress: an End-to-End Process}

\section{Experiments}
